import os
import faiss
import numpy as np
from openai import OpenAI
from dotenv import load_dotenv

# 1. Ladda API-nyckeln
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# 2. Dokument (kunskapsbas)
documents = [
    "Du √•terst√§ller l√∂senord genom att klicka p√• 'Gl√∂mt l√∂senord'.",
    "F√∂r att sp√•ra best√§llning, g√• till 'Mina best√§llningar' p√• ditt konto.",
    "Vi accepterar betalning via kort, PayPal och Swish.",
    "Returer √§r m√∂jliga inom 30 dagar fr√•n leverans.",
    "Kundtj√§nst n√•s via e-post eller telefon p√• hemsidan.",
]

# 3. Skapa embeddings och FAISS-index
def get_embedding(text):
    response = client.embeddings.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response.data[0].embedding

doc_embeddings = [get_embedding(doc) for doc in documents]
dimension = len(doc_embeddings[0])
index = faiss.IndexFlatL2(dimension)
index.add(np.array(doc_embeddings).astype('float32'))

# 4. Definiera retrieval-funktion
def get_docs(query):
    query_emb = get_embedding(query)
    D, I = index.search(np.array([query_emb]).astype('float32'), k=3)
    return "\n".join([documents[i] for i in I[0]])

# 5. Anv√§ndarfr√•ga
user_question = "Hur fungerar returer?"

# 6. Systemprompt med instruktion
system_prompt = """
Du √§r en hj√§lpsam assistent. Om du √§r os√§ker eller beh√∂ver fakta, anv√§nd get_docs genom att skriva:
{"action": "get_docs", "query": "min fr√•ga h√§r"}

Om du redan vet svaret, svara direkt.
"""

# 7. F√∂rsta AI-svar
response = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_question}
    ],
    temperature=0.3
).choices[0].message.content.strip()

print("üìù AI-svar:", response)

# 8. Om AI v√§ljer att anropa get_docs:
import json

try:
    action_json = json.loads(response)
    if action_json.get("action") == "get_docs":
        query = action_json.get("query")
        context = get_docs(query)

        follow_up_prompt = f"""
H√§r √§r informationen du bad om:

{context}

Besvara nu fr√•gan: {user_question}
"""
        follow_up_response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Du √§r en hj√§lpsam assistent."},
                {"role": "user", "content": follow_up_prompt}
            ],
            temperature=0.3
        ).choices[0].message.content.strip()

        print("\nüìö Slutgiltigt svar:", follow_up_response)

except json.JSONDecodeError:
    print("\n‚úÖ Ingen retrieval beh√∂vdes. Svaret var direkt.")

